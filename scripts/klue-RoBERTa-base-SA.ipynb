{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12f81c5",
   "metadata": {
    "id": "c12f81c5"
   },
   "source": [
    "# Binary Classification with BERT\n",
    "\n",
    "*Code is adapted from*\n",
    "- https://huggingface.co/transformers/v3.2.0/custom_datasets.html\n",
    "- https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
    "- https://luv-bansal.medium.com/fine-tuning-bert-for-text-classification-in-pytorch-503d97342db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac56b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/e9t/nsmc.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49bcdcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T03:45:32.103051Z",
     "start_time": "2022-05-17T03:45:30.458112Z"
    },
    "id": "f49bcdcf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, RobertaForSequenceClassification, AdamW\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb984286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:31.998406Z",
     "start_time": "2022-05-13T07:08:31.995970Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33061652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:32.066048Z",
     "start_time": "2022-05-13T07:08:31.999659Z"
    },
    "id": "33061652"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(70)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf992b28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:32.089524Z",
     "start_time": "2022-05-13T07:08:32.069360Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae42e58",
   "metadata": {
    "id": "dae42e58"
   },
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669e195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:32.101219Z",
     "start_time": "2022-05-13T07:08:32.092857Z"
    },
    "id": "8669e195"
   },
   "outputs": [],
   "source": [
    "def read_nsmc_split(path):\n",
    "    path = Path(path)\n",
    "    texts = list()\n",
    "    labels = list()\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "    df = df.dropna()\n",
    "    texts = df[\"document\"].to_list()\n",
    "    labels = df[\"label\"].to_list()\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61431e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:32.420550Z",
     "start_time": "2022-05-13T07:08:32.104366Z"
    },
    "id": "8b61431e"
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels = read_nsmc_split('nsmc/ratings_train.txt')\n",
    "test_texts, test_labels = read_nsmc_split('nsmc/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98c245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:32.461245Z",
     "start_time": "2022-05-13T07:08:32.421442Z"
    },
    "id": "4a98c245"
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c8469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:43.555769Z",
     "start_time": "2022-05-13T07:08:32.462165Z"
    },
    "id": "d48c8469",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99fa49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:49.103993Z",
     "start_time": "2022-05-13T07:08:43.557428Z"
    },
    "id": "dc99fa49",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128 # BERT can process upto 512 tokens, but it is too long for the Colab GPU to handle\n",
    "train_encodings = tokenizer(train_texts, max_length=MAX_LENGTH, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, max_length=MAX_LENGTH, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, max_length=MAX_LENGTH, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838bb691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:49.108516Z",
     "start_time": "2022-05-13T07:08:49.104885Z"
    },
    "id": "838bb691"
   },
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        super(BertDataset, self).__init__()\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):    \n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b1070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:49.124834Z",
     "start_time": "2022-05-13T07:08:49.109621Z"
    },
    "id": "c55b1070"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75142d71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:08:49.130693Z",
     "start_time": "2022-05-13T07:08:49.125883Z"
    },
    "id": "75142d71"
   },
   "outputs": [],
   "source": [
    "train_dataset = BertDataset(train_encodings, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = BertDataset(val_encodings, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = BertDataset(test_encodings, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c13e97",
   "metadata": {
    "id": "b4c13e97"
   },
   "source": [
    "## Step 2: Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f884e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:09:35.007242Z",
     "start_time": "2022-05-13T07:08:49.131643Z"
    },
    "id": "07f884e1"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('klue/roberta-base',\n",
    "                                                      num_labels = 2,\n",
    "                                                      output_attentions = False,\n",
    "                                                      output_hidden_states = False\n",
    "                                                     )\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c478590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:09:35.011704Z",
     "start_time": "2022-05-13T07:09:35.008475Z"
    },
    "id": "6c478590"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98a227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:09:35.024018Z",
     "start_time": "2022-05-13T07:09:35.012606Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "log_interval = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049eb39b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:09:35.031324Z",
     "start_time": "2022-05-13T07:09:35.024954Z"
    },
    "id": "049eb39b"
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f77eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:09:35.041756Z",
     "start_time": "2022-05-13T07:09:35.032484Z"
    },
    "id": "d51f77eb"
   },
   "outputs": [],
   "source": [
    "def finetune(epochs, train_loader, val_loader, model, optimizer):\n",
    "    \n",
    "    val_losses = list()\n",
    "    best_loss = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # ==========================\n",
    "        #           Train\n",
    "        # ==========================\n",
    "        print(\"Training epoch: \", epoch+1)\n",
    "\n",
    "        model.train()        \n",
    "        \n",
    "        for train_step, batch in enumerate(tqdm(train_loader)):\n",
    "            \n",
    "        \n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "            \n",
    "            loss=outputs.loss\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", loss.item(), train_step)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "                \n",
    "      \n",
    "        # ==========================\n",
    "        #           Validation\n",
    "        # ==========================\n",
    "        print(\"Validating epoch: \", epoch+1)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_accuracy = 0 \n",
    "        total_eval_loss = 0\n",
    "\n",
    "        for batch in tqdm(val_loader):\n",
    "\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                outputs = model(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "                total_eval_loss += loss.item()\n",
    "\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "                total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "        avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "        print(\"\\tAccuracy:{0:.2f}\".format(avg_val_accuracy))\n",
    "        \n",
    "        avg_val_loss = total_eval_loss / len(val_loader)\n",
    "        print(\"\\tValidation Loss:{0:.2f}\".format(avg_val_loss))\n",
    "        \n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        if len(val_losses) >= 2:\n",
    "            if avg_val_loss <= best_loss:\n",
    "                best_loss = avg_val_loss\n",
    "                best_model = model\n",
    "        else:\n",
    "            best_loss = avg_val_loss\n",
    "            best_model = model\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9843b65",
   "metadata": {
    "id": "c9843b65"
   },
   "source": [
    "## Step 3: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17793b76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T09:10:44.338684Z",
     "start_time": "2022-05-13T07:09:35.042813Z"
    },
    "id": "17793b76",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = finetune(4, train_loader, val_loader, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4iENFOeq5sur",
   "metadata": {
    "id": "4iENFOeq5sur"
   },
   "source": [
    "## Step 5: Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qA5hSdDa5u90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T09:10:44.831043Z",
     "start_time": "2022-05-13T09:10:44.339726Z"
    },
    "id": "qA5hSdDa5u90"
   },
   "outputs": [],
   "source": [
    "output_dir = \"../resources/model_save/klue-RoBERTa-base-SA\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf6b3fb",
   "metadata": {},
   "source": [
    "## Step 6: Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e249c73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T03:48:51.065058Z",
     "start_time": "2022-05-17T03:48:50.347098Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = \"../resources/model_save/klue-RoBERTa-base-SA\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PATH, local_files_only=True)\n",
    "model = RobertaForSequenceClassification.from_pretrained(PATH, local_files_only=True,\n",
    "                                                     num_labels=2,\n",
    "                                                     output_attentions = False,\n",
    "                                                      output_hidden_states = False\n",
    "                                                     )\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afc285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T03:48:51.356801Z",
     "start_time": "2022-05-17T03:48:51.352803Z"
    },
    "id": "8669e195"
   },
   "outputs": [],
   "source": [
    "def read_nsmc_split(path):\n",
    "    path = Path(path)\n",
    "    texts = list()\n",
    "    labels = list()\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "    df = df.dropna()\n",
    "    texts = df[\"document\"].to_list()\n",
    "    labels = df[\"label\"].to_list()\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf7d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T03:48:52.946613Z",
     "start_time": "2022-05-17T03:48:52.873603Z"
    },
    "id": "8b61431e"
   },
   "outputs": [],
   "source": [
    "test_texts, test_labels = read_nsmc_split('nsmc/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a6787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T03:48:53.603504Z",
     "start_time": "2022-05-17T03:48:53.597481Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc51703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T03:48:55.730964Z",
     "start_time": "2022-05-17T03:48:54.524297Z"
    },
    "id": "dc99fa49",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128 # BERT can process upto 512 tokens, but it is too long for the Colab GPU to handle\n",
    "test_encodings = tokenizer(test_texts, max_length=MAX_LENGTH, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f8f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T03:52:40.626387Z",
     "start_time": "2022-05-17T03:52:40.623551Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test_encodings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731993e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T09:10:47.949259Z",
     "start_time": "2022-05-13T09:10:47.945772Z"
    },
    "id": "838bb691"
   },
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        super(BertDataset, self).__init__()\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):    \n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfd788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T09:10:47.966529Z",
     "start_time": "2022-05-13T09:10:47.950134Z"
    },
    "id": "c55b1070"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb67b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T09:10:48.229616Z",
     "start_time": "2022-05-13T09:10:47.967525Z"
    },
    "id": "75142d71"
   },
   "outputs": [],
   "source": [
    "test_dataset = BertDataset(test_encodings, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541c1aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T09:10:48.240991Z",
     "start_time": "2022-05-13T09:10:48.238588Z"
    }
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30496fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T09:14:49.091552Z",
     "start_time": "2022-05-13T09:10:48.241854Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(test_loader)*BATCH_SIZE))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "total_test_accuracy = 0\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "\n",
    "    input_ids = batch['input_ids'].to(DEVICE)\n",
    "    attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "    labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, \n",
    "                      attention_mask=attention_mask)\n",
    "        logits = outputs['logits']\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "        total_test_accuracy += flat_accuracy(logits, label_ids)\n",
    "    \n",
    "avg_test_accuracy = total_test_accuracy / len(test_loader)\n",
    "    \n",
    "print('DONE.')\n",
    "\n",
    "print(\"Accuracy: {0:.2f}\".format(avg_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3cb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "F21NeE10_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (covid)",
   "language": "python",
   "name": "covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
